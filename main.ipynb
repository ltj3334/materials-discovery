{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "#from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...</td>\n",
       "      <td>0.631486</td>\n",
       "      <td>0.535060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>O[C@@H](CNC1CC1)CN1CCc2sccc2C1</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>1.116781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>N#CCCNC(=O)[C@@]1(O)CCSC1</td>\n",
       "      <td>1.463943</td>\n",
       "      <td>0.964848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.338862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                             SMILES   Reorg_g  \\\n",
       "0  train_0  CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...  0.631486   \n",
       "1  train_1                     O[C@@H](CNC1CC1)CN1CCc2sccc2C1  0.825901   \n",
       "2  train_2                          N#CCCNC(=O)[C@@]1(O)CCSC1  1.463943   \n",
       "3  train_3        COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1  0.166669   \n",
       "4  train_4          N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N  0.313820   \n",
       "\n",
       "   Reorg_ex  \n",
       "0  0.535060  \n",
       "1  1.116781  \n",
       "2  0.964848  \n",
       "3  0.161458  \n",
       "4  0.338862  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_set.ReorgE.csv\")\n",
    "train.columns = [\"index\", \"SMILES\", \"Reorg_g\", \"Reorg_ex\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 28297/36314 [02:03<00:35, 228.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13608\\531323166.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"ex_file/{file_name}\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;34m\"g\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"g_file/{file_name}\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mneed_text_wrapping\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mType\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"IOBase\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0ms3fs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mS3File\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mneed_text_wrapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRawIOBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS3File\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tj\\Anaconda3\\envs\\tensorflow\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"ex_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"ex_file\")\n",
    "\n",
    "if os.path.isdir(\"g_file\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(\"g_file\")\n",
    "\n",
    "train_mol = sorted(glob(\"data/mol_files/train_set/*.mol\"))\n",
    "\n",
    "for i in tqdm(train_mol):\n",
    "    result = []\n",
    "    tmp = open(i, 'r').read().split(\"\\n\")\n",
    "    for j in tmp:\n",
    "        tmp_ = re.sub(' +', ' ', j.lstrip()).split(' ')\n",
    "        if len(tmp_) > 11:\n",
    "            result.append(tmp_)\n",
    "            \n",
    "    file_name = i.split('\\\\')[-1].split('.')[0]\n",
    "    \n",
    "    if \"ex\" in file_name:\n",
    "        pd.DataFrame(result).to_csv(f\"ex_file/{file_name}\" + \".csv\", index = False)\n",
    "    elif \"g\" in file_name:\n",
    "        pd.DataFrame(result).to_csv(f\"g_file/{file_name}\" + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "error = []\n",
    "g_data, ex_data = [], []\n",
    "mol = []\n",
    "\n",
    "for i in tqdm(train[train.columns[0]]):\n",
    "    tmp_g = pd.read_csv(f\"g_file/{i}\" + '_g.csv')\n",
    "\n",
    "    if len(tmp_g) >= max_len:\n",
    "        max_len = len(tmp_g)\n",
    "        \n",
    "    for j in tmp_g[\"3\"]:\n",
    "        mol.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_list = list(set(mol))\n",
    "g_data, ex_data = [], []\n",
    "\n",
    "def get_mol(data):\n",
    "    if data in mol_list:\n",
    "        return mol_list.index(data) + 1\n",
    "    \n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "for i in tqdm(train[train.columns[0]]):\n",
    "    tmp_g = pd.read_csv(f\"g_file/{i}\" + '_g.csv').iloc[:, :4]\n",
    "    tmp_ex = pd.read_csv(f\"ex_file/{i}\" +'_ex.csv').iloc[:, :4]\n",
    "    \n",
    "    tmp_g[\"3\"] = tmp_g[\"3\"].apply(lambda x : get_mol(x))\n",
    "    tmp_ex[\"3\"] = tmp_ex[\"3\"].apply(lambda x : get_mol(x))\n",
    "    \n",
    "    tmp_g = np.array(tmp_g)\n",
    "    tmp_ex = np.array(tmp_ex)\n",
    "    \n",
    "    if max_len != len(tmp_g):\n",
    "        tmp_g = np.concatenate((tmp_g, np.array([[0] * 4] * (max_len-tmp_g.shape[0]))))\n",
    "        tmp_ex = np.concatenate((tmp_ex, np.array([[0] * 4] * (max_len - tmp_ex.shape[0]))))\n",
    "    elif max_len == len(tmp_g):\n",
    "        tmp_g = tmp_g\n",
    "        tmp_ex = tmp_ex\n",
    "    \n",
    "    g_data.append(tmp_g)\n",
    "    ex_data.append(tmp_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_data = np.array(g_data).reshape(len(g_data), -1)\n",
    "ex_data = np.array(ex_data).reshape(len(ex_data), -1)\n",
    "\n",
    "train_x = np.concatenate((g_data, ex_data), axis = 1)\n",
    "train_y = np.array(train.loc[:, [\"Reorg_g\", \"Reorg_ex\"]])\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f7b50985ffd4da1386000c948feaf8c0c359261878e332175a588f06b4ed379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
